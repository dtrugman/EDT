{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "if not logger.handlers:\n",
    "    logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_common import PERSONALITY_FEATURES, EMOTIONS_FEATURES, EMOTIONS_LABELS, DAA, CLUSTER\n",
    "\n",
    "from kmeans import KMeans\n",
    "from kmeans_printer import print_per_game_kmeans\n",
    "\n",
    "df = pd.read_csv('data/data_ellsberg.csv')\n",
    "df = df[PERSONALITY_FEATURES + EMOTIONS_FEATURES + [DAA]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 18\n",
    "K = 2\n",
    "\n",
    "km = KMeans(df[EMOTIONS_FEATURES], K, random_state=random_state)\n",
    "print_per_game_kmeans(km, EMOTIONS_LABELS, plot_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[CLUSTER] = km.labels\n",
    "df = df.drop(EMOTIONS_FEATURES, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symmetric_uncertainty import SUT\n",
    "\n",
    "class DecisionNode:\n",
    "    ID = 0\n",
    "\n",
    "    def __init__(self, df, min_gain, min_samples_leaf, index=None, columns=None):\n",
    "        self.__log = logging.getLogger('dt')\n",
    "\n",
    "        self.__id = DecisionNode.ID\n",
    "        DecisionNode.ID += 1\n",
    "        self.__ct = SUT(df, index, columns)\n",
    "\n",
    "        self.__min_samples_leaf = min_samples_leaf\n",
    "        self.__min_samples_split = 3 * self.__min_samples_leaf\n",
    "        self.__min_gain = min_gain\n",
    "\n",
    "        self.__param = None\n",
    "        self.__cutoff = None\n",
    "        self.__gain = 0\n",
    "        self.__left = None\n",
    "        self.__right = None\n",
    "\n",
    "        self.__fit()\n",
    "    \n",
    "    @property\n",
    "    def id(self):\n",
    "        return self.__id\n",
    "\n",
    "    @property\n",
    "    def ct(self):\n",
    "        return self.__ct\n",
    "\n",
    "    @property\n",
    "    def is_leaf(self):\n",
    "        return self.__left == None and self.__right == None\n",
    "\n",
    "    @property\n",
    "    def param(self):\n",
    "        return self.__param\n",
    "    \n",
    "    @property\n",
    "    def cutoff(self):\n",
    "        return self.__cutoff\n",
    "\n",
    "    @property\n",
    "    def left(self):\n",
    "        return self.__left\n",
    "\n",
    "    @property\n",
    "    def right(self):\n",
    "        return self.__right\n",
    "\n",
    "    @property\n",
    "    def metric(self):\n",
    "        return self.__ct.metric\n",
    "\n",
    "    @property\n",
    "    def subtree_metric(self):\n",
    "        if self.is_leaf:\n",
    "            return self.metric\n",
    "        else:\n",
    "            return self.left.metric + self.right.metric\n",
    "\n",
    "    def __find_cutoff(self, param, cutoff):\n",
    "        left_df = self.__ct.df[self.__ct.df[param] <= cutoff]\n",
    "        right_df = self.__ct.df[self.__ct.df[param] > cutoff]\n",
    "        return left_df, right_df\n",
    "        \n",
    "    def __find_cutoff_gain(self, current, param, cutoff):\n",
    "        left_df, right_df = self.__find_cutoff(param, cutoff)\n",
    "\n",
    "        left_len = len(left_df)\n",
    "        right_len = len(right_df)\n",
    "\n",
    "        if left_len < self.__min_samples_leaf or right_len < self.__min_samples_leaf:\n",
    "            self.__log.info(f'\\t\\t\\tNot enough samples in leaf: {left_len}, {right_len}')\n",
    "            return 0\n",
    "\n",
    "        left_ct = SUT(left_df, self.__ct.index, self.__ct.columns)\n",
    "        self.__log.debug('\\t\\t\\t' + '\\n\\t\\t\\t'.join(left_ct.df_p.to_string().split('\\n')))\n",
    "\n",
    "        left_metric = left_ct.metric\n",
    "        self.__log.info(f'\\t\\t\\tL: {left_metric}')\n",
    "\n",
    "        right_ct = SUT(right_df, self.__ct.index, self.__ct.columns)\n",
    "        self.__log.debug('\\t\\t\\t' + '\\n\\t\\t\\t'.join(right_ct.df_p.to_string().split('\\n')))\n",
    "\n",
    "        right_metric = right_ct.metric\n",
    "        self.__log.info(f'\\t\\t\\tR: {right_metric}')\n",
    "\n",
    "        return max(left_metric - current, right_metric - current)\n",
    "\n",
    "    def __find_best_cutoff_index(self, current, param):\n",
    "        best_cutoff = best_gain = None\n",
    "\n",
    "        values = sorted(self.__ct.df[param].unique())\n",
    "        cutoffs = [(values[i] + values[i+1]) / 2 for i in range(len(values) - 1)]\n",
    "        self.__log.info(f'\\t{values}')\n",
    "        np.random.shuffle(cutoffs)\n",
    "        for cutoff in cutoffs:\n",
    "            self.__log.info(f'\\t\\t{cutoff}')\n",
    "            gain = self.__find_cutoff_gain(current, param, cutoff)\n",
    "            self.__log.info(f'\\t\\t\\tGain: {gain}')\n",
    "            if not best_gain or gain > best_gain:\n",
    "                best_cutoff, best_gain = cutoff, gain\n",
    "\n",
    "        return best_cutoff, best_gain\n",
    "\n",
    "    def __find_best_cutoff(self, current):\n",
    "        best_param = best_cutoff = best_gain = None\n",
    "\n",
    "        params = PERSONALITY_FEATURES.copy()\n",
    "        np.random.shuffle(params)\n",
    "        for param in params:\n",
    "            self.__log.info(f'\\t{param}')\n",
    "            cutoff, gain = self.__find_best_cutoff_index(current, param)\n",
    "            self.__log.info(f'\\tBest gain for {param}: {gain}')\n",
    "\n",
    "            if not gain:\n",
    "                continue\n",
    "\n",
    "            if not best_gain or gain > best_gain:\n",
    "                best_param, best_cutoff, best_gain = param, cutoff, gain\n",
    "\n",
    "        return best_param, best_cutoff, best_gain \n",
    "\n",
    "    def __fit(self):\n",
    "        current = self.__ct.metric\n",
    "        self.__log.warning(f'Node #{self.__id} [{current}]')\n",
    "\n",
    "        if self.ct.len < self.__min_samples_split:\n",
    "            self.__log.warning(f'\\tNot splitting node, not enough samples')\n",
    "            return\n",
    "\n",
    "        self.__param, self.__cutoff, self.__gain = self.__find_best_cutoff(current)\n",
    "        if not self.__gain or self.__gain < self.__min_gain:\n",
    "            self.__log.warning('\\tNot splitting node, gain too low')\n",
    "            return\n",
    "\n",
    "        left_df, right_df = self.__find_cutoff(self.__param, self.__cutoff)\n",
    "\n",
    "        self.__log.warning(f'\\tBest gain: {self.__gain}\\n')\n",
    "        self.__log.warning('\\tLeft:\\t' + '\\n\\t'.join(str(SUT(left_df, self.__ct.index, self.__ct.columns)).split('\\n')))\n",
    "        self.__log.warning('\\tRight:\\t' + '\\n\\t'.join(str(SUT(right_df, self.__ct.index, self.__ct.columns)).split('\\n')))\n",
    "\n",
    "        self.__left = DecisionNode(left_df,\n",
    "                                   min_gain=self.__min_gain,\n",
    "                                   min_samples_leaf=self.__min_samples_leaf,\n",
    "                                   index=self.__ct.index,\n",
    "                                   columns=self.__ct.columns)\n",
    "        self.__right = DecisionNode(right_df,\n",
    "                                    min_gain=self.__min_gain,\n",
    "                                    min_samples_leaf=self.__min_samples_leaf,\n",
    "                                    index=self.__ct.index,\n",
    "                                    columns=self.__ct.columns)\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, df, min_gain, min_samples_leaf):\n",
    "        self.__root = DecisionNode(df,\n",
    "                                   min_gain=min_gain,\n",
    "                                   min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    @property\n",
    "    def root(self):\n",
    "        return self.__root\n",
    "\n",
    "logger = logging.getLogger('dt')\n",
    "logger.setLevel('WARNING')\n",
    "\n",
    "np.random.default_rng(seed=1337)\n",
    "dt = DecisionTree(df, min_gain=0.025, min_samples_leaf=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotPrinter:\n",
    "\n",
    "    def __init__(self, dt):\n",
    "        self.__dt = dt\n",
    "\n",
    "    def __node_children(self, node, left):\n",
    "        label = 'xlabel' if left else 'label'\n",
    "\n",
    "        operator = '<=' if left else '>'\n",
    "        criteria = f'{node.param} {operator} {node.cutoff}'\n",
    "\n",
    "        child = node.left if left else node.right\n",
    "        child_label = self.__node_label(child)\n",
    "        child_node = f'{child.id} [label=\"{child_label}\",shape=box,style=filled,color=\".7 .3 1.\"];'\n",
    "        child_edge = f'{node.id} -> {child.id} [{label}=\"{criteria}\"];'\n",
    "        return '\\n'.join([child_node, child_edge])\n",
    "\n",
    "    def __node_label(self, node):\n",
    "        len = node.ct.len\n",
    "        su = node.ct.metric\n",
    "        return f'id = {node.id}\\\\n' + \\\n",
    "               f'samples = {len}\\\\n' + \\\n",
    "               f'su = {su:.5f}\\\\n' + \\\n",
    "               f'cluster   0   1\\n' + \\\n",
    "               f'not-daa {node.ct.df_counts.loc[0].tolist()}\\n' + \\\n",
    "               f'daa       {node.ct.df_counts.loc[1].tolist()}'\n",
    "\n",
    "    def __node_content(self, node):\n",
    "        if node.is_leaf:\n",
    "            return ''\n",
    "\n",
    "        return '\\n'.join([\n",
    "            self.__node_children(node, left=True),\n",
    "            self.__node_content(node.left),\n",
    "            self.__node_children(node, left=False),\n",
    "            self.__node_content(node.right)\n",
    "        ])\n",
    "\n",
    "    def print(self):\n",
    "        node_label = self.__node_label(self.__dt.root)\n",
    "        node_content = self.__node_content(self.__dt.root)\n",
    "\n",
    "        return '\\n'.join([\n",
    "            'digraph BST {',\n",
    "            'node [fontname=\"Tahoma\"]',\n",
    "            f'{self.__dt.root.id} [label=\"{node_label}\",shape=box,style=filled,color=\".6 .2 1.\"];',\n",
    "            node_content,\n",
    "            '}'\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write report: Generate a DOT file and a PNG of the emotion decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "report_basename = 'ellsberg_emotion_decision_tree'\n",
    "\n",
    "report_dot = f'{report_basename}.{random_state}.dot'\n",
    "with open(report_dot, 'w') as fout:\n",
    "    dot_output = DotPrinter(dt)\n",
    "    fout.write(dot_output.print())\n",
    "\n",
    "report_png = f'{report_basename}.{random_state}.png'\n",
    "subprocess.check_call(['dot', report_dot, '-Tpng', f'-o{report_png}'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
