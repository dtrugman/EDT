{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Ellsberg data\n",
    "\n",
    "This notebook generates 'data_ellsberg.csv'. It processes the raw data and provides a standardised output:\n",
    "- Cleans up the results of the emotion elicitation questionnaire\n",
    "- Calculates a single locus score for each participant - See [original paper](https://psycnet.apa.org/record/2011-19211-001), page 11.\n",
    "- Calculates a Big 5 score (openness to experience, conscientiousness, extraversion, agreeableness, and emotional stability) for each participant - See [original paper](https://www.sciencedirect.com/science/article/abs/pii/S0092656603000461), appendix A.\n",
    "\n",
    "Notes:\n",
    "- The \"primary ID\" for our dataset throughout the entire process stays the index of the entry in `raw_data_ellsberg.csv`\n",
    "\n",
    "Exact cleaning steps:\n",
    "1. Remove duplicate column headers\n",
    "2. Remove exactly 3 participants with low progress (not enough data)\n",
    "3. Rename generic column names into useable ones\n",
    "4. Remove participant with multiple records (there should be exactly 1 participant to remove)\n",
    "5. Join against demographic data\n",
    "6. Convert game choice data types\n",
    "7. Convert certainty values data types \n",
    "8. Convert game emotions values data types\n",
    "9. Convert TIPI answer data types\n",
    "10. Calculate TIPI values\n",
    "11. Calculate locus values\n",
    "12. Add a column saying if the participant displays ambiguity aversion (DAA)\n",
    "13. Write processed output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ellsberg = 'data/raw_data_ellsberg.csv'\n",
    "demographic = 'data/raw_data_demographic.csv'\n",
    "output = 'data/data_ellsberg.csv'\n",
    "\n",
    "df = pd.read_csv(ellsberg)\n",
    "demographic_df = pd.read_csv(demographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Remove duplicate column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Remove exactly 3 participants with low progress (not enough data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'Progress': 'int32'})\n",
    "before = len(df)\n",
    "df = df[df['Progress'] >= 99]\n",
    "after = len(df)\n",
    "print(f'Removed {before - after} participants with low progess. Records left: {after}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Rename generic column names into useable ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"Q78\": \"participant_id\", \n",
    "\n",
    "    \"Q7\": \"ChoiceGame1\",\n",
    "    \"Q72\": \"CertaintyGame1\",\n",
    "    \"Q57_1\": \"Hopeful1A\",\n",
    "    \"Q58_1\": \"Curiosity1A\",\n",
    "    \"Q59_1\": \"Enlightenment1A\",\n",
    "    \"Q54_1\": \"Thrilled1A\",\n",
    "    \"Q61_1\": \"Anticipatory1A\",\n",
    "    \"Q56_1\": \"Satisfied1A\",\n",
    "    \"Q63_1\": \"Hopeful1B\",\n",
    "    \"Q64_1\": \"Curiosity1B\",\n",
    "    \"Q65_1\": \"Enlightenment1B\",\n",
    "    \"Q66_1\": \"Thrilled1B\",\n",
    "    \"Q67_1\": \"Anticipatory1B\",\n",
    "    \"Q68_1\": \"Satisfied1B\",\n",
    "    \"Q13\": \"ChoiceGame2\",\n",
    "    \"Q14\": \"CertaintyGame2\",\n",
    "    \"Q15_1\": \"Hopeful2A\",\n",
    "    \"Q52_1\": \"Curiosity2A\",\n",
    "    \"Q53_1\": \"Enlightenment2A\",\n",
    "    \"Q60_1\": \"Thrilled2A\",\n",
    "    \"Q55_1\": \"Anticipatory2A\",\n",
    "    \"Q62_1\": \"Satisfied2A\",\n",
    "    \"Q69_1\": \"Hopeful2B\",\n",
    "    \"Q70_1\": \"Curiosity2B\",\n",
    "    \"Q71_1\": \"Enlightenment2B\",\n",
    "    \"Q72_1\": \"Thrilled2B\",\n",
    "    \"Q73_1\": \"Anticipatory2B\",\n",
    "    \"Q74_1\": \"Satisfied2B\",\n",
    "    \"Q17_1\": \"TipiEnthusiastic\",\n",
    "    \"Q17_2\": \"TipiQuiet\",\n",
    "    \"Q17_3\": \"TipiWarm\",\n",
    "    \"Q17_4\": \"TipiQuarrelsome\",\n",
    "    \"Q17_5\": \"TipiDisciplined\",\n",
    "    \"Q17_6\": \"TipiCareless\",\n",
    "    \"Q17_7\": \"TipiStable\",\n",
    "    \"Q17_8\": \"TipiAnxious\",\n",
    "    \"Q17_9\": \"TipiComplex\",\n",
    "    \"Q17_10\": \"TipiUncreative\",\n",
    "\n",
    "    \"Q15\": \"Locus1\",\n",
    "    \"Q17\": \"Locus2\",\n",
    "    \"Q19\": \"Locus3\",\n",
    "    \"Q21\": \"Locus4\",\n",
    "    \"Q23\": \"Locus5\",\n",
    "    \"Q25\": \"Locus6\",\n",
    "    \"Q27\": \"Locus7\",\n",
    "    \"Q29\": \"Locus8\",\n",
    "    \"Q31\": \"Locus9\",\n",
    "    \"Q33\": \"Locus10\",\n",
    "    \"Q35\": \"Locus11\",\n",
    "    \"Q37\": \"Locus12\",\n",
    "    \"Q39\": \"Locus13\",\n",
    "    \"Q41\": \"Locus14\",\n",
    "    \"Q43\": \"Locus15\",\n",
    "    \"Q45\": \"Locus16\",\n",
    "    \"Q47\": \"Locus17\",\n",
    "    \"Q49\": \"Locus18\",\n",
    "    \"Q51\": \"Locus19\",\n",
    "    \"Q53\": \"Locus20\",\n",
    "    \"Q55\": \"Locus21\",\n",
    "    \"Q57\": \"Locus22\",\n",
    "    \"Q59\": \"Locus23\",\n",
    "    \"Q61\": \"Locus24\",\n",
    "    \"Q63\": \"Locus25\",\n",
    "    \"Q65\": \"Locus26\",\n",
    "    \"Q67\": \"Locus27\",\n",
    "    \"Q69\": \"Locus28\",\n",
    "    \"Q71\": \"Locus29\",\n",
    "}\n",
    "\n",
    "df = df[mapping.keys()]\n",
    "df = df.rename(columns=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Remove participant with multiple records (there should be exactly 1 participant to remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find participants with multiple records\n",
    "count = df['participant_id'].value_counts()\n",
    "\n",
    "before = len(df)\n",
    "\n",
    "# Remove all records from participants with more than one record\n",
    "for id, n in count[count > 1].items():\n",
    "    print(f'Removing {n} records for {id}')\n",
    "    df = df[df['participant_id'] != id]\n",
    "\n",
    "after = len(df)\n",
    "\n",
    "print(f'Removed {before - after} records from same participants. Records left: {after}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Join against demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_cols = ['participant_id', 'Sex', 'Age']\n",
    "demographic_df = demographic_df[demographic_cols]\n",
    "\n",
    "# Add the index of 'df' as a new column\n",
    "before = len(df)\n",
    "\n",
    "df['index'] = df.index\n",
    "df = pd.merge(df, demographic_df, on='participant_id')\n",
    "\n",
    "# Restore index from original 'df'\n",
    "df.index = df['index']\n",
    "df = df.drop(columns=['index'])\n",
    "\n",
    "after = len(df)\n",
    "print(f'Removed {before - after} participants without demographic information. Records left: {after}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Convert game choice data types\n",
    "\n",
    "If the participant chose lottery A, set the value as (numeric) 1, otherwise, set the value as (numeric) 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_cols = ['ChoiceGame1', 'ChoiceGame2']\n",
    "for col in choice_cols:\n",
    "    df[col] = np.where(df[col] == 'Lottery A', 1, 2)\n",
    "\n",
    "choice_dtype = {c: 'int32' for c in choice_cols}\n",
    "df = df.astype(choice_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Convert game certainty data types\n",
    "\n",
    "Remove text values from game certainty columns, and cast to numeric types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canonicalize values for game certainty\n",
    "\n",
    "certainty_cols = ['CertaintyGame1', 'CertaintyGame2']\n",
    "for col in certainty_cols:\n",
    "    df = df.replace({col: {'Very Uncertain\\n1': 1, 'Very Certain\\n5': 5}})\n",
    "\n",
    "certainty_dtype = {c: 'int32' for c in certainty_cols}\n",
    "df = df.astype(certainty_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Convert game emotions data types\n",
    "\n",
    "For every emotion (hopeful, curiosity, enlightment, thrilled, anticipatory, satisfied), replace categorical values (enums) with numeric ones (1-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopeful_columns = [ 'Hopeful1A', 'Hopeful1B', 'Hopeful2A', 'Hopeful2B' ]\n",
    "curiosity_columns = [ 'Curiosity1A', 'Curiosity1B', 'Curiosity2A', 'Curiosity2B' ]\n",
    "enlightenment_columns = [ 'Enlightenment1A', 'Enlightenment1B', 'Enlightenment2A', 'Enlightenment2B' ]\n",
    "thrilled_columns = [ 'Thrilled1A', 'Thrilled1B', 'Thrilled2A', 'Thrilled2B' ]\n",
    "anticipatory_columns = [ 'Anticipatory1A', 'Anticipatory1B', 'Anticipatory2A', 'Anticipatory2B' ]\n",
    "satisfied_columns = [ 'Satisfied1A', 'Satisfied1B', 'Satisfied2A', 'Satisfied2B' ]\n",
    "\n",
    "hopeful_values = {'Worry': 1, 'Discomfort': 2, 'Comfort': 3, 'Hopeful': 4}\n",
    "curiosity_values = {'Boredom': 1, 'Indifference': 2, 'Interest': 3, 'Curiosity': 4}\n",
    "enlightenment_values = {'Puzzlement': 1, 'Confusion': 2, 'Insight': 3, 'Enlightenment': 4}\n",
    "thrilled_values = {'Disappointed': 1, 'Dissatisfied': 2, 'Satisfied': 3, 'Thrilled': 4}\n",
    "anticipatory_values = {'Dread': 1, 'Apprehension': 2, 'Calm': 3, 'Anticipatory': 4}\n",
    "satisfied_values = {'Embarrassed': 1, 'Self-conscious': 2, 'Pleased': 3, 'Satisfied': 4}\n",
    "\n",
    "mapping = [\n",
    "    (hopeful_columns, hopeful_values),\n",
    "    (curiosity_columns, curiosity_values),\n",
    "    (enlightenment_columns, enlightenment_values),\n",
    "    (thrilled_columns, thrilled_values),\n",
    "    (anticipatory_columns, anticipatory_values),\n",
    "    (satisfied_columns, satisfied_values)\n",
    "]\n",
    "\n",
    "for columns, values in mapping:\n",
    "    numeric_mapping = {column: values for column in columns}\n",
    "    df = df.replace(numeric_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Convert TIPI answer data types\n",
    "\n",
    "Remove textual values and cast to numeric types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipi_cols = [\n",
    "    \"TipiEnthusiastic\",\n",
    "    \"TipiQuiet\",\n",
    "    \"TipiWarm\",\n",
    "    \"TipiQuarrelsome\",\n",
    "    \"TipiDisciplined\",\n",
    "    \"TipiCareless\",\n",
    "    \"TipiStable\",\n",
    "    \"TipiAnxious\",\n",
    "    \"TipiComplex\",\n",
    "    \"TipiUncreative\",\n",
    "]\n",
    "\n",
    "# Remove strings for '1' and '7' values\n",
    "for col in tipi_cols:\n",
    "    df = df.replace({col: {'1 strongly\\ndisagree': 1, '7 strongly\\nagree': 7}})\n",
    "\n",
    "# Update tipi columns to be integers\n",
    "tipi_dtype_mapping = {col: 'int32' for col in tipi_cols}\n",
    "df = df.astype(tipi_dtype_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Calculate TIPI values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map columns to the question numbers in the TIPI calculation document\n",
    "tipi_mapping = {\n",
    "    \"Tipi1\": \"TipiEnthusiastic\",\n",
    "    \"Tipi6\": \"TipiQuiet\",\n",
    "    \"Tipi7\": \"TipiWarm\",\n",
    "    \"Tipi2\": \"TipiQuarrelsome\",\n",
    "    \"Tipi3\": \"TipiDisciplined\",\n",
    "    \"Tipi8\": \"TipiCareless\",\n",
    "    \"Tipi9\": \"TipiStable\",\n",
    "    \"Tipi4\": \"TipiAnxious\",\n",
    "    \"Tipi5\": \"TipiComplex\",\n",
    "    \"Tipi10\": \"TipiUncreative\",\n",
    "}\n",
    "\n",
    "# Calculate Big5\n",
    "big5 = ['Openess', 'Conciensiousness', 'Extroversion', 'Agreability', 'Stability']\n",
    "\n",
    "def tipi_score(major, minor):\n",
    "    major_col = tipi_mapping[major]\n",
    "    minor_col = tipi_mapping[minor]\n",
    "    return (df[major_col] + (8 - df[minor_col])) / 2\n",
    "\n",
    "df['Openess'] = tipi_score('Tipi9', 'Tipi10')\n",
    "df['Conciensiousness'] = tipi_score('Tipi5', 'Tipi6')\n",
    "df['Extroversion'] = tipi_score('Tipi1', 'Tipi2')\n",
    "df['Agreability'] = tipi_score('Tipi3', 'Tipi4')\n",
    "df['Stability'] = tipi_score('Tipi7', 'Tipi8')\n",
    "\n",
    "print(df[big5].mean())\n",
    "\n",
    "# Averages from Journal:\n",
    "# Conciensiousness = 4.61\n",
    "# Agreability = 4.69\n",
    "# Stability = 4.34\n",
    "# Openess = 5.51\n",
    "# Extroversion = 3.98\n",
    "\n",
    "# Remove raw columns\n",
    "df = df.drop(tipi_mapping.values(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11: Calculate locus values\n",
    "\n",
    "- Replaces categorical values (textual answers) with numerical values of 1 (first answer) and 2 (second answer)\n",
    "- Adds a column per question that says if the participant should get a point for that answer or not\n",
    "- Calculates a single column with the aggregated locus score per participant\n",
    "\n",
    "Note: Questions 1, 8, 14, 19, 24 and 27 are not scored, see the Locus questionnaire for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This mapping helps convert textual values to option they chose, i.e. a numeric 1 or 2\n",
    "# Questions that are not scored simply don't appear here\n",
    "locus_choice_mapping = {\n",
    "    '1': 'Children',\n",
    "    '2': 'Many',\n",
    "    '3': 'One',\n",
    "    '4': 'In',\n",
    "    '5': 'The',\n",
    "    '6': 'Without',\n",
    "    '7': 'No',\n",
    "    '8': 'Heredity',\n",
    "    '9': 'I',\n",
    "    '10': 'In',\n",
    "    '11': 'Becoming',\n",
    "    '12': 'The',\n",
    "    '13': 'When',\n",
    "    '14': 'There',\n",
    "    '15': 'In',\n",
    "    '16': 'Who',\n",
    "    '17': 'As',\n",
    "    '18': 'Most',\n",
    "    '19': 'One',\n",
    "    '20': 'It',\n",
    "    '21': 'In',\n",
    "    '22': 'With',\n",
    "    '23': 'Sometimes',\n",
    "    '24': 'A good leader expects',\n",
    "    '25': 'Many',\n",
    "    '26': 'People',\n",
    "    '27': 'There',\n",
    "    '28': 'What',\n",
    "    '29': 'Most',\n",
    "}\n",
    "\n",
    "# This mapping helps convert participant answers to scoring, i.e. a numeric 1 if they are should get a point, otherwise 0\n",
    "# Questions that are not scored are compared against '$', which will never appear, so the score will always be 0\n",
    "locus_score_mapping = {\n",
    "    '1': '$',\n",
    "    '2': 'Many',\n",
    "    '3': 'There',\n",
    "    '4': 'Unfortunately',\n",
    "    '5': 'Most',\n",
    "    '6': 'Without',\n",
    "    '7': 'No',\n",
    "    '8': '$',\n",
    "    '9': 'I',\n",
    "    '10': 'Many',\n",
    "    '11': 'Getting',\n",
    "    '12': 'This',\n",
    "    '13': 'It',\n",
    "    '14': '$',\n",
    "    '15': 'Many',\n",
    "    '16': 'Who',\n",
    "    '17': 'As',\n",
    "    '18': 'Most',\n",
    "    '19': '$',\n",
    "    '20': 'It',\n",
    "    '21': 'In',\n",
    "    '22': 'It',\n",
    "    '23': 'Sometimes',\n",
    "    '24': '$',\n",
    "    '25': 'Many',\n",
    "    '26': 'There',\n",
    "    '27': '$',\n",
    "    '28': 'Sometimes',\n",
    "    '29': 'Most',\n",
    "}\n",
    "\n",
    "# This conversion has to come first, as the next one overrides the original textual answers\n",
    "for k, v in locus_score_mapping.items():\n",
    "    locus_k = 'Locus' + k\n",
    "    score_k = 'LocusScore' + k\n",
    "    df[score_k] = np.where(df[locus_k].str.startswith(v, na=False), 1, 0)\n",
    "\n",
    "# Override the textual answers with numerical values\n",
    "for k, v in locus_choice_mapping.items():\n",
    "    locus_k = 'Locus' + k\n",
    "    df[locus_k] = np.where(df[locus_k].str.startswith(v, na=False), 1, 2)\n",
    "\n",
    "# Calculate a single locus score column\n",
    "score_keys = ['LocusScore' + dk for dk in locus_score_mapping]\n",
    "df['Locus'] = df[score_keys].sum(axis=1)\n",
    "df['Locus'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12: Add a column saying if the participant displays ambiguity aversion (DAA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDAA(x):\n",
    "    if x['ChoiceGame1'] == 1 and x['ChoiceGame2'] == 2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df['DAA'] = df.apply(isDAA, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 13: Write processed output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output, index=True, index_label='ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
