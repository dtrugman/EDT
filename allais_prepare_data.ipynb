{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Allais data\n",
    "\n",
    "This notebook generates 'data_allais.csv'. It processes the raw data and provides a standardised output:\n",
    "- Cleans up the results of the emotion elicitation questionnaire\n",
    "- Calculates a single locus score for each participant - See [original paper](https://psycnet.apa.org/record/2011-19211-001), page 11.\n",
    "- Calculates a Big 5 score (openness to experience, conscientiousness, extraversion, agreeableness, and emotional stability) for each participant - See [original paper](https://www.sciencedirect.com/science/article/abs/pii/S0092656603000461), appendix A.\n",
    "\n",
    "Notes:\n",
    "- The \"primary ID\" for our dataset throughout the entire process stays the index of the entry in `raw_data_allais.csv`\n",
    "\n",
    "Exact cleaning steps:\n",
    "1. Remove duplicate column headers \n",
    "2. Remove exactly 4 participants with low progress (not enough data)\n",
    "3. Rename generic column names into useable ones\n",
    "4. Remove participant with multiple records (there should be no such participants)\n",
    "5. Join against demographic data (drop 5 participants without demographic information)\n",
    "6. Adjust game choice values & data types\n",
    "7. Adjust certainty values & data types \n",
    "8. Adjust game emotions values & data types\n",
    "9. Adjust TIPI answer values & data types\n",
    "10. Calculate TIPI values\n",
    "11. Calculate locus values\n",
    "12. Add a column saying if the participant displays ambiguity aversion (DAA)\n",
    "13. Write processed output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "allais = 'data/raw_data_allais.csv'\n",
    "demographic = f'data/demographic_allais.csv'\n",
    "output = f'data/data_allais.csv'\n",
    "\n",
    "df = pd.read_csv(allais)\n",
    "demographic_df = pd.read_csv(demographic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Remove duplicate column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Remove exactly 3 participants with low progress (not enough data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'Progress': 'int32'})\n",
    "before = len(df)\n",
    "df = df[df['Progress'] >= 99]\n",
    "after = len(df)\n",
    "print(f'Removed {before - after} participants with low progess. Records left: {after}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Rename generic column names into useable ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    \"Q89\": \"participant_id\", \n",
    "\n",
    "    \"Q5\": \"ChoiceGame1\",\n",
    "    \"Q51\": \"CertaintyGame1\",\n",
    "    \"Q6_1\": \"Hopeful1A\",\n",
    "    \"Q55_1\": \"Curiosity1A\",\n",
    "    \"Q56_1\": \"Enlightenment1A\",\n",
    "    \"Q57_1\": \"Thrilled1A\",\n",
    "    \"Q58_1\": \"Anticipatory1A\",\n",
    "    \"Q59_1\": \"Satisfied1A\",\n",
    "    \"Q60_1\": \"Hopeful1B\",\n",
    "    \"Q61_1\": \"Curiosity1B\",\n",
    "    \"Q62_1\": \"Enlightenment1B\",\n",
    "    \"Q63_1\": \"Thrilled1B\",\n",
    "    \"Q64_1\": \"Anticipatory1B\",\n",
    "    \"Q65_1\": \"Satisfied1B\",\n",
    "    \"Q82\": \"ChoiceGame2\",\n",
    "    \"Q54\": \"CertaintyGame2\",\n",
    "    \"Q66_1\": \"Hopeful2A\",\n",
    "    \"Q67_1\": \"Curiosity2A\",\n",
    "    \"Q68_1\": \"Enlightenment2A\",\n",
    "    \"Q69_1\": \"Thrilled2A\",\n",
    "    \"Q70_1\": \"Anticipatory2A\",\n",
    "    \"Q71_1\": \"Satisfied2A\",\n",
    "    \"Q72_1\": \"Hopeful2B\",\n",
    "    \"Q73_1\": \"Curiosity2B\",\n",
    "    \"Q74_1\": \"Enlightenment2B\",\n",
    "    \"Q75_1\": \"Thrilled2B\",\n",
    "    \"Q76_1\": \"Anticipatory2B\",\n",
    "    \"Q77_1\": \"Satisfied2B\",\n",
    "    \"Q16_1\": \"TipiEnthusiastic\",\n",
    "    \"Q16_2\": \"TipiQuiet\",\n",
    "    \"Q16_3\": \"TipiWarm\",\n",
    "    \"Q16_4\": \"TipiQuarrelsome\",\n",
    "    \"Q16_5\": \"TipiDisciplined\",\n",
    "    \"Q16_6\": \"TipiCareless\",\n",
    "    \"Q16_7\": \"TipiStable\",\n",
    "    \"Q16_8\": \"TipiAnxious\",\n",
    "    \"Q16_9\": \"TipiComplex\",\n",
    "    \"Q16_10\": \"TipiUncreative\",\n",
    "\n",
    "    \"Q18\": \"Locus1\",\n",
    "    \"Q19\": \"Locus2\",\n",
    "    \"Q21\": \"Locus3\",\n",
    "    \"Q22\": \"Locus4\",\n",
    "    \"Q23\": \"Locus5\",\n",
    "    \"Q24\": \"Locus6\",\n",
    "    \"Q25\": \"Locus7\",\n",
    "    \"Q26\": \"Locus8\",\n",
    "    \"Q27\": \"Locus9\",\n",
    "    \"Q28\": \"Locus10\",\n",
    "    \"Q29\": \"Locus11\",\n",
    "    \"Q30\": \"Locus12\",\n",
    "    \"Q31\": \"Locus13\",\n",
    "    \"Q32\": \"Locus14\",\n",
    "    \"Q33\": \"Locus15\",\n",
    "    \"Q34\": \"Locus16\",\n",
    "    \"Q35\": \"Locus17\",\n",
    "    \"Q36\": \"Locus18\",\n",
    "    \"Q37\": \"Locus19\",\n",
    "    \"Q38\": \"Locus20\",\n",
    "    \"Q39\": \"Locus21\",\n",
    "    \"Q40\": \"Locus22\",\n",
    "    \"Q41\": \"Locus23\",\n",
    "    \"Q42\": \"Locus24\",\n",
    "    \"Q43\": \"Locus25\",\n",
    "    \"Q44\": \"Locus26\",\n",
    "    \"Q45\": \"Locus27\",\n",
    "    \"Q46\": \"Locus28\",\n",
    "    \"Q47\": \"Locus29\",\n",
    "}\n",
    "\n",
    "count = sum([1 for k in mapping if k in df])\n",
    "print(f'{count}/{len(mapping)} of keys found')\n",
    "\n",
    "df = df[mapping.keys()]\n",
    "df = df.rename(columns=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Remove participant with multiple records (there should be exactly 1 participant to remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find participants with multiple records\n",
    "count = df['participant_id'].value_counts()\n",
    "\n",
    "before = len(df)\n",
    "\n",
    "# Remove all records from participants with more than one record\n",
    "for id, n in count[count > 1].items():\n",
    "    print(f'Removing {n} records for {id}')\n",
    "    df = df[df['participant_id'] != id]\n",
    "\n",
    "after = len(df)\n",
    "\n",
    "print(f'Removed {before - after} records from same participants. Records left: {after}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Join against demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_cols = ['participant_id', 'Sex', 'Age']\n",
    "demographic_df = demographic_df[demographic_cols]\n",
    "\n",
    "# Add the index of 'df' as a new column\n",
    "before = len(df)\n",
    "\n",
    "df['index'] = df.index\n",
    "df = pd.merge(df, demographic_df, on='participant_id')\n",
    "\n",
    "# Restore index from original 'df'\n",
    "df.index = df['index']\n",
    "df = df.drop(columns=['index'])\n",
    "\n",
    "after = len(df)\n",
    "print(f'Removed {before - after} participants without demographic information. Records left: {after}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Adjust game choice values & data types\n",
    "\n",
    "If the participant chose lottery A, set the value as (numeric) 1, otherwise, set the value as (numeric) 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_cols = ['ChoiceGame1', 'ChoiceGame2']\n",
    "for col in choice_cols:\n",
    "    df[col] = np.where(df[col] == '1', 1, 2)\n",
    "\n",
    "choice_dtype = {c: 'int32' for c in choice_cols}\n",
    "df = df.astype(choice_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Adjust game certainty values & data types\n",
    "\n",
    "Make sure certainty values are numeric integrals, 1 (very uncertain) - 5 (very certain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "certainty_cols = ['CertaintyGame1', 'CertaintyGame2']\n",
    "for col in certainty_cols:\n",
    "    print(df[col].value_counts())\n",
    "\n",
    "df = df.astype({c: 'int32' for c in certainty_cols})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Adjust game emotions values & data types\n",
    "\n",
    "For every emotion (hopeful, curiosity, enlightment, thrilled, anticipatory, satisfied), adjust scale (1, 6, 7, 8) to 1-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopeful_columns = [ 'Hopeful1A', 'Hopeful1B', 'Hopeful2A', 'Hopeful2B' ]\n",
    "curiosity_columns = [ 'Curiosity1A', 'Curiosity1B', 'Curiosity2A', 'Curiosity2B' ]\n",
    "enlightenment_columns = [ 'Enlightenment1A', 'Enlightenment1B', 'Enlightenment2A', 'Enlightenment2B' ]\n",
    "thrilled_columns = [ 'Thrilled1A', 'Thrilled1B', 'Thrilled2A', 'Thrilled2B' ]\n",
    "anticipatory_columns = [ 'Anticipatory1A', 'Anticipatory1B', 'Anticipatory2A', 'Anticipatory2B' ]\n",
    "satisfied_columns = [ 'Satisfied1A', 'Satisfied1B', 'Satisfied2A', 'Satisfied2B' ]\n",
    "all_columns = hopeful_columns + curiosity_columns + enlightenment_columns + \\\n",
    "    thrilled_columns + anticipatory_columns + satisfied_columns\n",
    "\n",
    "value_mapping = {\n",
    "    '1': 1,\n",
    "    '6': 2,\n",
    "    '7': 3,\n",
    "    '8': 4,\n",
    "}\n",
    "\n",
    "for col in all_columns:\n",
    "    df[col] = df[col].replace(value_mapping)\n",
    "\n",
    "df = df.astype({c: 'int32' for c in all_columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9: Adjust TIPI answer values & data types\n",
    "\n",
    "Remove textual values and cast to numeric types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipi_cols = [\n",
    "    \"TipiEnthusiastic\",\n",
    "    \"TipiQuiet\",\n",
    "    \"TipiWarm\",\n",
    "    \"TipiQuarrelsome\",\n",
    "    \"TipiDisciplined\",\n",
    "    \"TipiCareless\",\n",
    "    \"TipiStable\",\n",
    "    \"TipiAnxious\",\n",
    "    \"TipiComplex\",\n",
    "    \"TipiUncreative\",\n",
    "]\n",
    "\n",
    "# Update tipi columns to be integers\n",
    "df = df.astype({col: 'int32' for col in tipi_cols})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10: Calculate TIPI values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map columns to the question numbers in the TIPI calculation document\n",
    "tipi_mapping = {\n",
    "    \"Tipi1\": \"TipiEnthusiastic\",\n",
    "    \"Tipi6\": \"TipiQuiet\",\n",
    "    \"Tipi7\": \"TipiWarm\",\n",
    "    \"Tipi2\": \"TipiQuarrelsome\",\n",
    "    \"Tipi3\": \"TipiDisciplined\",\n",
    "    \"Tipi8\": \"TipiCareless\",\n",
    "    \"Tipi9\": \"TipiStable\",\n",
    "    \"Tipi4\": \"TipiAnxious\",\n",
    "    \"Tipi5\": \"TipiComplex\",\n",
    "    \"Tipi10\": \"TipiUncreative\",\n",
    "}\n",
    "\n",
    "# Calculate Big5\n",
    "big5 = ['Openness', 'Conscientiousness', 'Extroversion', 'Agreeability', 'Stability']\n",
    "\n",
    "def tipi_score(major, minor):\n",
    "    major_col = tipi_mapping[major]\n",
    "    minor_col = tipi_mapping[minor]\n",
    "    return (df[major_col] + (8 - df[minor_col])) / 2\n",
    "\n",
    "df['Openness'] = tipi_score('Tipi9', 'Tipi10')\n",
    "df['Conscientiousness'] = tipi_score('Tipi5', 'Tipi6')\n",
    "df['Extroversion'] = tipi_score('Tipi1', 'Tipi2')\n",
    "df['Agreeability'] = tipi_score('Tipi3', 'Tipi4')\n",
    "df['Stability'] = tipi_score('Tipi7', 'Tipi8')\n",
    "\n",
    "print(df[big5].mean())\n",
    "\n",
    "# Averages from Journal:\n",
    "# Conscientiousness = 4.61\n",
    "# Agreeability = 4.69\n",
    "# Stability = 4.34\n",
    "# Openness = 5.51\n",
    "# Extroversion = 3.98\n",
    "\n",
    "# Remove raw columns\n",
    "df = df.drop(tipi_mapping.values(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11: Calculate locus values\n",
    "\n",
    "- Replaces categorical values (textual answers) with numerical values of 1 (first answer) and 2 (second answer)\n",
    "- Adds a column per question that says if the participant should get a point for that answer or not\n",
    "- Calculates a single column with the aggregated locus score per participant\n",
    "\n",
    "Note: Questions 1, 8, 14, 19, 24 and 27 are not scored, see the Locus questionnaire for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw values correlate with the option they chose, i.e. a numeric 1 or 2\n",
    "\n",
    "# This mapping helps convert participant answers to scoring, i.e. a numeric 1 if they are should get a point, otherwise 0\n",
    "# Questions that are not scored are compared against '-1', which will never appear, so the score will always be 0\n",
    "locus_score_mapping = {\n",
    "    '1': '-1',\n",
    "    '2': '1',\n",
    "    '3': '2',\n",
    "    '4': '2',\n",
    "    '5': '2',\n",
    "    '6': '1',\n",
    "    '7': '1',\n",
    "    '8': '-1',\n",
    "    '9': '1',\n",
    "    '10': '2',\n",
    "    '11': '2',\n",
    "    '12': '2',\n",
    "    '13': '2',\n",
    "    '14': '-1',\n",
    "    '15': '2',\n",
    "    '16': '1',\n",
    "    '17': '1',\n",
    "    '18': '1',\n",
    "    '19': '-1',\n",
    "    '20': '1',\n",
    "    '21': '1',\n",
    "    '22': '2',\n",
    "    '23': '1',\n",
    "    '24': '-1',\n",
    "    '25': '1',\n",
    "    '26': '2',\n",
    "    '27': '-1',\n",
    "    '28': '2',\n",
    "    '29': '1',\n",
    "}\n",
    "\n",
    "# This conversion has to come first, as the next one overrides the original textual answers\n",
    "for k, v in locus_score_mapping.items():\n",
    "    locus_k = 'Locus' + k\n",
    "    score_k = 'LocusScore' + k\n",
    "    df[score_k] = np.where(df[locus_k] == v, 1, 0)\n",
    "\n",
    "# Calculate a single locus score column\n",
    "score_keys = ['LocusScore' + dk for dk in locus_score_mapping]\n",
    "df['Locus'] = df[score_keys].sum(axis=1)\n",
    "\n",
    "# Draw raw score columns\n",
    "df = df.drop(score_keys, axis=1)\n",
    "\n",
    "df['Locus'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12: Add a column saying if the participant displays ambiguity aversion (DAA)\n",
    "\n",
    "Allais paradox deals with the interesting observation that when presented with game 1 most people would choose gamble A,\n",
    "but when presented with game 2 most people would choose gamble B.\n",
    "This phenomenon is familiar as the \"certainty effect\" and it is paradoxical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isDAA(x):\n",
    "    if x['ChoiceGame1'] == 1 and x['ChoiceGame2'] == 2:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "df['DAA'] = df.apply(isDAA, axis=1)\n",
    "df['DAA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 13: Write processed output CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output, index=True, index_label='ID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
